"""
ä¸‹è½½çœŸå®æ··å‡åœŸæŠ—å‹å¼ºåº¦æ•°æ®é›†
æ¥æºï¼šKaggle - Concrete Compressive Strength Dataset
"""

import kagglehub
import pandas as pd
import shutil
from pathlib import Path

print("=" * 80)
print("ä¸‹è½½çœŸå®æ··å‡åœŸæŠ—å‹å¼ºåº¦æ•°æ®é›†")
print("=" * 80)
print()

# ä¸‹è½½æ•°æ®é›†
print("ğŸ“¦ æ­£åœ¨ä» Kaggle ä¸‹è½½æ•°æ®é›†...")
path = kagglehub.dataset_download("elikplim/concrete-compressive-strength-data-set")

print(f"âœ“ æ•°æ®é›†ä¸‹è½½å®Œæˆ")
print(f"è·¯å¾„: {path}")
print()

# æŸ¥æ‰¾CSVæ–‡ä»¶
print("ğŸ“‚ æŸ¥æ‰¾æ•°æ®æ–‡ä»¶...")
dataset_path = Path(path)
csv_files = list(dataset_path.glob("*.csv"))

if not csv_files:
    # å¯èƒ½åœ¨å­ç›®å½•ä¸­
    csv_files = list(dataset_path.glob("**/*.csv"))

print(f"æ‰¾åˆ° {len(csv_files)} ä¸ªCSVæ–‡ä»¶:")
for f in csv_files:
    print(f"  â€¢ {f.name}")

# åŠ è½½ä¸»æ•°æ®æ–‡ä»¶
if csv_files:
    main_file = csv_files[0]
    print(f"\nğŸ“Š åŠ è½½æ•°æ®æ–‡ä»¶: {main_file.name}")
    df = pd.read_csv(main_file)
    
    print(f"\næ•°æ®æ¦‚è§ˆ:")
    print(f"  æ ·æœ¬æ•°: {len(df)}")
    print(f"  å­—æ®µæ•°: {len(df.columns)}")
    print(f"\nåˆ—å:")
    for i, col in enumerate(df.columns, 1):
        print(f"  {i}. {col}")
    
    print(f"\nå‰5è¡Œæ•°æ®:")
    print(df.head())
    
    print(f"\næ•°æ®ç»Ÿè®¡:")
    print(df.describe())
    
    print(f"\næ•°æ®ç±»å‹:")
    print(df.dtypes)
    
    print(f"\nç¼ºå¤±å€¼:")
    print(df.isnull().sum())
    
    # å¤åˆ¶åˆ°é¡¹ç›®æ•°æ®ç›®å½•
    target_dir = Path("data/real")
    target_dir.mkdir(parents=True, exist_ok=True)
    target_file = target_dir / "concrete_compressive_strength.csv"
    
    shutil.copy(main_file, target_file)
    print(f"\nâœ“ æ•°æ®å·²å¤åˆ¶åˆ°: {target_file}")
    
else:
    print("âŒ æœªæ‰¾åˆ°CSVæ–‡ä»¶")

print("\n" + "=" * 80)
print("âœ… ä¸‹è½½å®Œæˆ")
print("=" * 80)

