"""
å› æœé©±åŠ¨çš„æ™ºèƒ½ä½“ç³»ç»Ÿ - åŸºäº LangGraph
ä¸‰æ™ºèƒ½ä½“æ¶æ„ï¼šRouter Agent â†’ Causal Analyst Agent â†’ Advisor Agent

åº”ç”¨åœºæ™¯ï¼šæ··å‡åœŸé›†æ–™è´¨é‡æ§åˆ¶ä¸å·¥è‰ºä¼˜åŒ–
"""

import os
import pickle
from pathlib import Path
from typing import TypedDict, Literal, Dict, Any, Optional
from langchain_core.tools import tool
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, START, END
import pandas as pd
import numpy as np
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# å¯¼å…¥æ··å‡åœŸé›†æ–™å› æœæ¨¡å‹
from causal_model import ConcreteAggregateCausalModel


# ============================================================================
# å…¨å±€é…ç½®
# ============================================================================

OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')
OPENAI_API_BASE = os.getenv('OPENAI_API_BASE', 'https://api.openai.com/v1')
OPENAI_MODEL = os.getenv('OPENAI_MODEL', 'gpt-4o-mini')


# ============================================================================
# ç¬¬ä¸€æ­¥ï¼šå®šä¹‰ State
# ============================================================================

class CausalAnalysisState(TypedDict):
    """å› æœåˆ†ææ™ºèƒ½ä½“ç³»ç»Ÿçš„å…±äº«çŠ¶æ€"""
    # ç”¨æˆ·è¾“å…¥
    user_query: str                    # åŸå§‹æŸ¥è¯¢
    reference_sample_index: int        # å‚è€ƒæ‰¹æ¬¡ç´¢å¼•ï¼ˆç”¨äºåäº‹å®åˆ†æï¼Œå¯é€‰ï¼‰
    observed_config: dict              # ç”¨æˆ·è¾“å…¥çš„è§‚æµ‹é…æ¯”ï¼ˆç”¨äºåäº‹å®åˆ†æï¼Œå¯é€‰ï¼Œä¼˜å…ˆäºreference_sample_indexï¼‰
    
    # Router è¾“å‡º
    analysis_type: str                 # 'attribution' | 'intervention' | 'counterfactual'
    target_variable: str               # ç›®æ ‡å˜é‡
    intervention_params: dict          # å¹²é¢„å‚æ•°
    routing_reasoning: str             # è·¯ç”±æ¨ç†è¿‡ç¨‹
    target_improvement: float          # ç›®æ ‡æå‡å¹…åº¦ï¼ˆç™¾åˆ†æ¯”ï¼Œå¦‚10è¡¨ç¤ºæå‡10%ï¼‰
    specified_variables: list          # ç”¨æˆ·æŒ‡å®šè¦è°ƒæ•´çš„å˜é‡åˆ—è¡¨
    target_value: float                # ç”¨æˆ·æŒ‡å®šçš„ç›®æ ‡å€¼ï¼ˆå¦‚"å¼ºåº¦è¾¾åˆ°45"ä¸­çš„45ï¼‰
    
    # Causal Analyst è¾“å‡º
    causal_results: dict               # å› æœåˆ†ææ•°å€¼ç»“æœ
    analysis_summary: str              # åˆ†ææ‘˜è¦
    
    # Optimizer è¾“å‡ºï¼ˆæ–°å¢ï¼‰
    optimized_config: dict             # ä¼˜åŒ–åçš„é…æ¯”å»ºè®®
    predicted_strength: float          # é¢„æµ‹çš„å¼ºåº¦
    optimization_summary: str          # ä¼˜åŒ–æ‘˜è¦
    base_sample_info: dict             # åŸºå‡†æ ·æœ¬ä¿¡æ¯ï¼ˆå½“ä½¿ç”¨é»˜è®¤æ ·æœ¬æ—¶ï¼‰
    
    # Advisor è¾“å‡º
    recommendations: str               # å†³ç­–å»ºè®®
    
    # ç³»ç»Ÿå…ƒæ•°æ®
    error: Optional[str]               # é”™è¯¯ä¿¡æ¯


# ============================================================================
# ç¬¬äºŒæ­¥ï¼šå®šä¹‰å·¥å…·å‡½æ•° - åŒ…è£…ç°æœ‰å› æœæ¨¡å‹
# ============================================================================

# å…¨å±€å› æœæ¨¡å‹å®ä¾‹
_causal_model_instance: Optional[ConcreteAggregateCausalModel] = None

# æ¨¡å‹ç¼“å­˜è·¯å¾„
MODEL_CACHE_FILE = Path("models/causal_model.pkl")


def build_sample_info_dict(sample: pd.Series, source: str = "é»˜è®¤") -> dict:
    """
    æ„å»ºæ ·æœ¬ä¿¡æ¯å­—å…¸
    
    Args:
        sample: pandas Seriesï¼ŒåŒ…å«æ ·æœ¬çš„æ‰€æœ‰å­—æ®µ
        source: æ ·æœ¬æ¥æºè¯´æ˜ï¼ˆå¦‚"é»˜è®¤"ã€"ç”¨æˆ·é€‰æ‹©"ç­‰ï¼‰
    
    Returns:
        åŒ…å«æ ·æœ¬å®Œæ•´ä¿¡æ¯çš„å­—å…¸
    """
    return {
        "source": source,
        "cement": float(sample['cement']),
        "blast_furnace_slag": float(sample['blast_furnace_slag']),
        "fly_ash": float(sample['fly_ash']),
        "water": float(sample['water']),
        "superplasticizer": float(sample['superplasticizer']),
        "coarse_aggregate": float(sample['coarse_aggregate']),
        "fine_aggregate": float(sample['fine_aggregate']),
        "age": int(sample['age']),
        "concrete_compressive_strength": float(sample['concrete_compressive_strength'])
    }


def initialize_causal_model(df: pd.DataFrame = None, force_retrain: bool = False) -> ConcreteAggregateCausalModel:
    """
    åˆå§‹åŒ–æ··å‡åœŸé›†æ–™å› æœæ¨¡å‹ï¼ˆæ”¯æŒç¼“å­˜åŠ è½½ï¼‰
    
    Args:
        df: æ··å‡åœŸé›†æ–™æ•°æ®ï¼ˆå¦‚æœä»ç¼“å­˜åŠ è½½åˆ™å¯ä»¥ä¸º Noneï¼‰
        force_retrain: æ˜¯å¦å¼ºåˆ¶é‡æ–°è®­ç»ƒï¼ˆé»˜è®¤ Falseï¼Œä¼˜å…ˆä½¿ç”¨ç¼“å­˜ï¼‰
        
    Returns:
        åˆå§‹åŒ–å¥½çš„å› æœæ¨¡å‹
    """
    global _causal_model_instance
    
    # ä¼˜å…ˆå°è¯•ä»ç¼“å­˜åŠ è½½
    if not force_retrain and MODEL_CACHE_FILE.exists():
        print("ğŸ“¦ ä»ç¼“å­˜åŠ è½½å› æœæ¨¡å‹...")
        try:
            with open(MODEL_CACHE_FILE, 'rb') as f:
                model = pickle.load(f)
            _causal_model_instance = model
            print(f"âœ“ æ¨¡å‹åŠ è½½å®Œæˆ (ç¼“å­˜æ–‡ä»¶: {MODEL_CACHE_FILE})")
            print(f"  â€¢ èŠ‚ç‚¹æ•°: {model.causal_graph.number_of_nodes()}")
            print(f"  â€¢ è¾¹æ•°: {model.causal_graph.number_of_edges()}")
            return model
        except Exception as e:
            print(f"âš ï¸  ç¼“å­˜åŠ è½½å¤±è´¥: {e}")
            print("   å°†é‡æ–°è®­ç»ƒæ¨¡å‹...")
    
    # å¦‚æœç¼“å­˜ä¸å­˜åœ¨æˆ–åŠ è½½å¤±è´¥ï¼Œé‡æ–°è®­ç»ƒ
    if df is None:
        raise ValueError(
            "æœªæ‰¾åˆ°ç¼“å­˜æ¨¡å‹ä¸”æœªæä¾›æ•°æ®ã€‚è¯·å…ˆè¿è¡Œ train_causal_model.py è®­ç»ƒæ¨¡å‹ï¼Œ"
            "æˆ–è€…åœ¨è°ƒç”¨æ—¶æä¾›æ•°æ®ã€‚"
        )
    
    print("ğŸ”§ è®­ç»ƒæ–°çš„å› æœæ¨¡å‹ï¼ˆé¦–æ¬¡è¿è¡Œéœ€è¦1-2åˆ†é’Ÿï¼‰...")
    model = ConcreteAggregateCausalModel(df)
    model.build_causal_graph()
    model.fit_causal_model(quality='BETTER', invertible=True)
    
    # ä¿å­˜åˆ°ç¼“å­˜
    MODEL_CACHE_FILE.parent.mkdir(parents=True, exist_ok=True)
    with open(MODEL_CACHE_FILE, 'wb') as f:
        pickle.dump(model, f)
    print(f"âœ“ æ¨¡å‹è®­ç»ƒå®Œæˆå¹¶ä¿å­˜è‡³: {MODEL_CACHE_FILE}")
    
    _causal_model_instance = model
    return model


@tool
def attribution_analysis_tool(
    target_variable: str,
    old_period_start: int,
    old_period_end: int,
    new_period_start: int,
    new_period_end: int
) -> dict:
    """
    æ‰§è¡Œå½’å› åˆ†æï¼Œè¯†åˆ«ç›®æ ‡å˜é‡å˜åŒ–çš„æ ¹æœ¬åŸå› ã€‚
    
    ç”¨äºå›ç­”"ä¸ºä»€ä¹ˆå«æ³¥é‡ä¸Šå‡äº†ï¼Ÿ"ã€"æ˜¯ä»€ä¹ˆå¯¼è‡´å¼ºåº¦ä¸‹é™ï¼Ÿ"ç­‰é—®é¢˜ã€‚
    å¯¹æ¯”ä¸¤ä¸ªæ—¶é—´æ®µçš„æ•°æ®ï¼Œæ‰¾å‡ºå“ªäº›å› ç´ å¯¹ç›®æ ‡å˜é‡çš„å˜åŒ–è´¡çŒ®æœ€å¤§ã€‚
    
    Args:
        target_variable: ç›®æ ‡å˜é‡ï¼ˆå¦‚ 'mud_content_pct', 'concrete_strength_mpa'ï¼‰
        old_period_start: æ—§æ—¶æœŸèµ·å§‹ç´¢å¼•
        old_period_end: æ—§æ—¶æœŸç»“æŸç´¢å¼•
        new_period_start: æ–°æ—¶æœŸèµ·å§‹ç´¢å¼•
        new_period_end: æ–°æ—¶æœŸç»“æŸç´¢å¼•
        
    Returns:
        dict: åŒ…å«å„å› ç´ è´¡çŒ®åº¦çš„åˆ†æç»“æœ
    """
    if _causal_model_instance is None:
        return {"error": "å› æœæ¨¡å‹æœªåˆå§‹åŒ–"}
    
    try:
        df = _causal_model_instance.df
        df_old = df.iloc[old_period_start:old_period_end]
        df_new = df.iloc[new_period_start:new_period_end]
        
        contributions, uncertainties = _causal_model_instance.attribution_analysis(
            df_old=df_old,
            df_new=df_new,
            target_column=target_variable,
            num_samples=2000,
            num_bootstrap_resamples=4
        )
        
        # æŒ‰è´¡çŒ®åº¦æ’åº
        sorted_contributions = sorted(
            contributions.items(), 
            key=lambda x: abs(x[1]), 
            reverse=True
        )
        
        # å°† numpy æ•°ç»„è½¬æ¢ä¸º Python åŸç”Ÿç±»å‹
        def convert_to_native(val):
            """è½¬æ¢ numpy ç±»å‹ä¸º Python åŸç”Ÿç±»å‹"""
            if val is None:
                return None
            if isinstance(val, np.ndarray):
                return val.tolist()
            if isinstance(val, (np.floating, np.integer)):
                return float(val)
            if isinstance(val, tuple):
                return tuple(convert_to_native(v) for v in val)
            return val
        
        result = {
            "type": "attribution",
            "target": target_variable,
            "top_factors": [
                {
                    "variable": var,
                    "contribution": float(contrib),
                    "confidence_interval": convert_to_native(uncertainties.get(var, (None, None)))
                }
                for var, contrib in sorted_contributions[:5]
            ],
            "old_period_size": len(df_old),
            "new_period_size": len(df_new)
        }
        
        return result
        
    except Exception as e:
        return {"error": str(e)}


@tool
def intervention_analysis_tool(
    target_variable: str,
    step_size: float = 1.0
) -> dict:
    """
    æ‰§è¡Œå¹²é¢„åˆ†æï¼Œè¯„ä¼°å„å› ç´ å¯¹ç›®æ ‡å˜é‡çš„å› æœæ•ˆåº”ã€‚
    
    ç”¨äºå›ç­”"å¦‚ä½•é™ä½å«æ³¥é‡ï¼Ÿ"ã€"å“ªäº›å·¥è‰ºå‚æ•°æœ€æœ‰æ•ˆï¼Ÿ"ç­‰é—®é¢˜ã€‚
    è®¡ç®—æ¯ä¸ªå¯æ§å˜é‡å¢åŠ ä¸€ä¸ªå•ä½åï¼Œå¯¹ç›®æ ‡å˜é‡çš„å½±å“ç¨‹åº¦ã€‚
    
    Args:
        target_variable: ç›®æ ‡å˜é‡ï¼ˆå¦‚ 'mud_content_pct', 'concrete_strength_mpa'ï¼‰
        step_size: å¹²é¢„æ­¥é•¿ï¼ˆé»˜è®¤ä¸º1.0ï¼‰
        
    Returns:
        dict: åŒ…å«å„å˜é‡å› æœæ•ˆåº”çš„åˆ†æç»“æœ
    """
    if _causal_model_instance is None:
        return {"error": "å› æœæ¨¡å‹æœªåˆå§‹åŒ–"}
    
    try:
        results_df = _causal_model_instance.intervention_analysis(
            target=target_variable,
            step_size=step_size,
            num_samples=10000,
            num_bootstrap_resamples=40
        )
        
        # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
        interventions = []
        for _, row in results_df.iterrows():
            interventions.append({
                "variable": row['Variable'],
                "causal_effect": float(row['Causal_Effect']),
                "confidence_interval": (float(row['Lower_CI']), float(row['Upper_CI'])),
                "std_error": float(row.get('Std_Error', 0))
            })
        
        result = {
            "type": "intervention",
            "target": target_variable,
            "step_size": step_size,
            "interventions": interventions
        }
        
        return result
        
    except Exception as e:
        return {"error": str(e)}


@tool
def math_calculator_tool(
    variable: str,
    base_value: float,
    operation: str,
    operand: float
) -> float:
    """
    æ•°å­¦è®¡ç®—å·¥å…·ï¼Œå¤„ç†å˜é‡çš„åŠ å‡ä¹˜é™¤è¿ç®—
    
    Args:
        variable: å˜é‡åç§°
        base_value: åŸºå‡†å€¼
        operation: è¿ç®—ç±»å‹ ('add'/'subtract'/'multiply'/'divide')
        operand: æ“ä½œæ•°
        
    Returns:
        float: è®¡ç®—ç»“æœ
    """
    if operation == 'add':
        result = base_value + operand
    elif operation == 'subtract':
        result = base_value - operand
    elif operation == 'multiply':
        result = base_value * operand
    elif operation == 'divide':
        if operand == 0:
            raise ValueError(f"é™¤æ•°ä¸èƒ½ä¸º0")
        result = base_value / operand
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„è¿ç®—ç±»å‹: {operation}")
    
    print(f"  ğŸ§® è®¡ç®—: {variable} = {base_value} {operation} {operand} = {result}")
    return result


@tool
def counterfactual_analysis_tool(
    sample_index: int,
    interventions: dict,
    target_variable: str
) -> dict:
    """
    æ‰§è¡Œåäº‹å®åˆ†æï¼Œé¢„æµ‹"å¦‚æœæ”¹å˜æŸäº›å˜é‡ï¼Œç»“æœä¼šå¦‚ä½•"ã€‚
    
    ç”¨äºå›ç­”"å¦‚æœæ”¹å˜æ°´èƒ¶æ¯”ä¼šæ€æ ·ï¼Ÿ"ã€"æ¢ä¸ªäº§åœ°èƒ½è¾¾æ ‡å—ï¼Ÿ"ç­‰é—®é¢˜ã€‚
    é’ˆå¯¹å…·ä½“çš„å†å²æ ·æœ¬ï¼Œæ¨¡æ‹Ÿæ”¹å˜ä¸€ä¸ªæˆ–å¤šä¸ªå˜é‡åçš„ç»“æœã€‚
    
    Args:
        sample_index: æ ·æœ¬ç´¢å¼•ï¼ˆè¦åˆ†æçš„å†å²è®°å½•ï¼‰
        interventions: å¹²é¢„å˜é‡åŠå…¶æ–°å€¼çš„å­—å…¸ï¼Œå¦‚ {"water_binder_ratio": 0.43, "cement_content": 379}
        target_variable: ç›®æ ‡å˜é‡åç§°
        
    Returns:
        dict: åŒ…å«å®é™…å€¼ã€åäº‹å®å€¼å’Œå˜åŒ–çš„ç»“æœ
    """
    if _causal_model_instance is None:
        return {"error": "å› æœæ¨¡å‹æœªåˆå§‹åŒ–"}
    
    try:
        df = _causal_model_instance.df
        
        # éªŒè¯ç´¢å¼•æ˜¯å¦åœ¨èŒƒå›´å†…
        if sample_index < 0 or sample_index >= len(df):
            return {"error": f"æ ·æœ¬ç´¢å¼• {sample_index} è¶…å‡ºèŒƒå›´ [0, {len(df)-1}]"}
        
        observed_data = df.iloc[[sample_index]]
        
        # è½¬æ¢å¹²é¢„å€¼ä¸ºfloat
        interventions_float = {k: float(v) for k, v in interventions.items()}
        
        result_dict = _causal_model_instance.counterfactual_analysis(
            observed_data=observed_data,
            interventions=interventions_float,
            target=target_variable,
            num_samples=1000
        )
        
        # è½¬æ¢ä¸ºåŸç”Ÿ Python ç±»å‹
        def to_float(val):
            """å®‰å…¨åœ°è½¬æ¢ä¸º float"""
            if val is None:
                return None
            if isinstance(val, (np.floating, np.integer, np.ndarray)):
                return float(val)
            return float(val)
        
        # æ„å»ºå¹²é¢„ä¿¡æ¯åˆ—è¡¨
        intervention_list = []
        for var, new_val in interventions_float.items():
            original_val = to_float(observed_data[var].values[0]) if var in observed_data.columns else None
            intervention_list.append({
                "variable": var,
                "original_value": original_val,
                "new_value": float(new_val)
            })
        
        result = {
            "type": "counterfactual",
            "sample_index": sample_index,
            "target": target_variable,
            "interventions": intervention_list,  # ç°åœ¨æ˜¯åˆ—è¡¨ï¼Œæ”¯æŒå¤šä¸ªå¹²é¢„
            "observed_mean": to_float(result_dict['observed_mean']),
            "counterfactual_mean": to_float(result_dict['counterfactual_mean']),
            "causal_effect": to_float(result_dict['causal_effect'])
        }
        
        return result
        
    except Exception as e:
        return {"error": str(e)}


# ============================================================================
# ç¬¬ä¸‰æ­¥ï¼šå®šä¹‰ä¸‰ä¸ªæ™ºèƒ½ä½“èŠ‚ç‚¹
# ============================================================================

def router_agent(state: CausalAnalysisState) -> dict:
    """
    Router Agentï¼šç†è§£ç”¨æˆ·æŸ¥è¯¢ï¼Œè¯†åˆ«åˆ†æç±»å‹å’Œå…³é”®å‚æ•°
    
    èŒè´£ï¼š
    1. ç†è§£è‡ªç„¶è¯­è¨€æŸ¥è¯¢çš„æ„å›¾
    2. è¯†åˆ«æŸ¥è¯¢ç±»å‹ï¼ˆå½’å› /å¹²é¢„/åäº‹å®ï¼‰
    3. æå–å…³é”®ä¿¡æ¯ï¼ˆç›®æ ‡å˜é‡ã€å¹²é¢„å‚æ•°ç­‰ï¼‰
    
    æ³¨æ„ï¼šå¦‚æœ state ä¸­å·²ç»æœ‰ specified_variables æˆ– target_valueï¼Œä¼˜å…ˆä½¿ç”¨å®ƒä»¬
    """
    print("\nğŸ” Router Agent æ­£åœ¨åˆ†ææ‚¨çš„é—®é¢˜...")
    
    # æ£€æŸ¥æ˜¯å¦å·²ç»ä»APIä¼ å…¥äº†å‚æ•°
    api_specified_variables = state.get('specified_variables')
    api_target_value = state.get('target_value')
    
    if api_specified_variables:
        print(f"  ğŸ“Œ æ£€æµ‹åˆ°APIä¼ å…¥çš„è°ƒæ•´å˜é‡: {', '.join(api_specified_variables)}")
    if api_target_value:
        print(f"  ğŸ“Œ æ£€æµ‹åˆ°APIä¼ å…¥çš„ç›®æ ‡å€¼: {api_target_value}")
    
    # ä½¿ç”¨ LLM ç†è§£ç”¨æˆ·æŸ¥è¯¢
    llm = ChatOpenAI(
        model=OPENAI_MODEL,
        temperature=0.1,
        openai_api_key=OPENAI_API_KEY,
        base_url=OPENAI_API_BASE
    )
    
    prompt = f"""ä½ æ˜¯ä¸€ä¸ªå› æœåˆ†æç³»ç»Ÿçš„è·¯ç”±ä¸“å®¶ã€‚è¯·åˆ†æç”¨æˆ·çš„æŸ¥è¯¢ï¼Œç¡®å®šåº”è¯¥æ‰§è¡Œå“ªç§å› æœåˆ†æã€‚

ã€åº”ç”¨åœºæ™¯ã€‘é«˜æ€§èƒ½æ··å‡åœŸé…åˆæ¯”è®¾è®¡ä¸å¼ºåº¦ä¼˜åŒ–ï¼ˆåŸºäºUCIçœŸå®æ•°æ®é›†ï¼ŒYeh 1998ï¼‰

ã€åˆ†æç±»å‹ã€‘
1. **attribution**ï¼ˆå½’å› åˆ†æï¼‰- ç”¨äºå›ç­”"ä¸ºä»€ä¹ˆXXå˜åŒ–äº†ï¼Ÿ"ã€"åŸå› æ˜¯ä»€ä¹ˆï¼Ÿ"
   - å¯¹æ¯”ä¸¤ä¸ªæ—¶æœŸçš„æ•°æ®ï¼Œè¯†åˆ«å¯¼è‡´ç›®æ ‡å˜é‡å˜åŒ–çš„æ ¹æœ¬åŸå› 

2. **intervention**ï¼ˆå¹²é¢„åˆ†æï¼‰- ç”¨äºå›ç­”"å¦‚ä½•æ”¹è¿›XXï¼Ÿ"ã€"å“ªä¸ªå› ç´ æœ€æœ‰æ•ˆï¼Ÿ"
   - è¯„ä¼°ä¸åŒæªæ–½çš„æ•ˆæœï¼Œæ‰¾å‡ºæœ€æœ‰å½±å“åŠ›çš„å¯æ§å˜é‡

3. **counterfactual**ï¼ˆåäº‹å®åˆ†æï¼‰- ç”¨äºå›ç­”"å¦‚æœ...ä¼šæ€æ ·ï¼Ÿ"
   - é’ˆå¯¹å…·ä½“æ¡ˆä¾‹æ¨¡æ‹Ÿå‡è®¾åœºæ™¯ï¼Œé¢„æµ‹æ”¹å˜æŸä¸ªå˜é‡åçš„ç»“æœ
   - **å¿…é¡»ä»ç”¨æˆ·é—®é¢˜ä¸­æå–**ï¼šå¹²é¢„å˜é‡åã€åŸå§‹å€¼ã€æ–°å€¼

ã€å› æœå›¾å¯ç”¨å˜é‡ã€‘ï¼ˆåŸºäºUCIçœŸå®æ•°æ®é›†ï¼Œä»…9ä¸ªåŸå§‹å˜é‡ï¼‰

1. cement: æ°´æ³¥ (102-540 kg/mÂ³, å‡å€¼281) **ã€å…³é”®ææ–™ã€‘**
2. blast_furnace_slag: é«˜ç‚‰çŸ¿æ¸£ (0-359 kg/mÂ³, å‡å€¼74) - æé«˜å¯†å®åº¦å’Œè€ä¹…æ€§
3. fly_ash: ç²‰ç…¤ç° (0-200 kg/mÂ³, å‡å€¼54) - ç«å±±ç°ååº”ï¼Œé•¿æœŸå¼ºåº¦
4. water: æ°´ (122-247 kg/mÂ³, å‡å€¼182) **ã€Abramså®šå¾‹ï¼šæ°´è¶Šå¤šå¼ºåº¦è¶Šä½ã€‘**
5. superplasticizer: é«˜æ•ˆå‡æ°´å‰‚ (0-32 kg/mÂ³, å‡å€¼6.2) - ä¸æ°´è´Ÿç›¸å…³ï¼ˆr=-0.66ï¼‰
6. coarse_aggregate: ç²—éª¨æ–™ (801-1145 kg/mÂ³, å‡å€¼973) - éª¨æ¶ä½œç”¨
7. fine_aggregate: ç»†éª¨æ–™ (594-993 kg/mÂ³, å‡å€¼774) - å¡«å……ä½œç”¨
8. age: é¾„æœŸ (1-365å¤©, å‡å€¼46å¤©) **ã€æ—¶é—´æ•ˆåº”ã€‘**
9. concrete_compressive_strength: æŠ—å‹å¼ºåº¦ (2.3-82.6 MPa, å‡å€¼35.8) **ã€ç›®æ ‡å˜é‡ã€‘**

ç”¨æˆ·æŸ¥è¯¢ï¼š"{state['user_query']}"

ã€å˜é‡è¯†åˆ«è§„åˆ™ã€‘
- ç”¨æˆ·æåˆ°"å¼ºåº¦"/"æŠ—å‹å¼ºåº¦"/"æ··å‡åœŸå¼ºåº¦" â†’ concrete_compressive_strength
- ç”¨æˆ·æåˆ°"æ°´æ³¥"/"æ°´æ³¥ç”¨é‡" â†’ cement
- ç”¨æˆ·æåˆ°"çŸ¿æ¸£"/"é«˜ç‚‰çŸ¿æ¸£"/"çŸ¿ç²‰" â†’ blast_furnace_slag  
- ç”¨æˆ·æåˆ°"ç²‰ç…¤ç°" â†’ fly_ash
- ç”¨æˆ·æåˆ°"æ°´"/"ç”¨æ°´é‡"/"æ‹Œåˆæ°´" â†’ water
- ç”¨æˆ·æåˆ°"å‡æ°´å‰‚"/"å¤–åŠ å‰‚"/"é«˜æ•ˆå‡æ°´å‰‚"/"è¶…å¡‘åŒ–å‰‚" â†’ superplasticizer
- ç”¨æˆ·æåˆ°"ç²—éª¨æ–™"/"çŸ³å­"/"ç¢çŸ³" â†’ coarse_aggregate
- ç”¨æˆ·æåˆ°"ç»†éª¨æ–™"/"ç ‚"/"æ²³ç ‚" â†’ fine_aggregate
- ç”¨æˆ·æåˆ°"é¾„æœŸ"/"å…»æŠ¤æ—¶é—´"/"å¤©æ•°"/"é¾„é¾„" â†’ age

æ³¨æ„ï¼šæœ¬æ¨¡å‹ä½¿ç”¨çœŸå®UCIæ•°æ®é›†çš„9ä¸ªåŸå§‹å˜é‡ï¼Œæœªä½¿ç”¨è¡ç”Ÿå˜é‡

è¯·ä»¥JSONæ ¼å¼å›å¤ï¼š
{{
    "analysis_type": "attribution/intervention/counterfactual",
    "target_variable": "ä»ä¸Šè¿°å˜é‡åˆ—è¡¨ä¸­é€‰æ‹©ï¼ˆå¿…é¡»æ˜¯å‡†ç¡®çš„å˜é‡åï¼‰",
    "reasoning": "ä½ çš„æ¨ç†è¿‡ç¨‹ï¼ˆ1-2å¥è¯ï¼‰",
    "target_improvement": ç›®æ ‡æå‡ç™¾åˆ†æ¯”ï¼ˆå¦‚ç”¨æˆ·è¯´"æå‡10%"åˆ™ä¸º10ï¼Œå¦‚æœæ²¡æœ‰æ˜ç¡®æåŠåˆ™ä¸ºnullï¼‰,
    "target_value": ç”¨æˆ·æŒ‡å®šçš„ç›®æ ‡å€¼ï¼ˆå¦‚"å¼ºåº¦è¾¾åˆ°45"åˆ™ä¸º45ï¼Œå¦‚æœæ²¡æœ‰æ˜ç¡®æåŠåˆ™ä¸ºnullï¼‰,
    "specified_variables": ["ç”¨æˆ·æ˜ç¡®è¦æ±‚è°ƒæ•´çš„å˜é‡åˆ—è¡¨ï¼Œå¦‚cementã€fly_ashï¼Œå¦‚æœæ²¡æœ‰åˆ™ä¸ºç©ºåˆ—è¡¨"],
    "extracted_info": {{
        // å¦‚æœæ˜¯åäº‹å®åˆ†æï¼š
        // æƒ…å†µA - ç»å¯¹å€¼å¹²é¢„ï¼ˆæ˜ç¡®ç»™å‡ºæ–°å€¼ï¼‰ï¼š
        "intervention_variable": "å˜é‡å",
        "original_value": åŸå§‹æ•°å€¼,
        "intervention_value": æ–°æ•°å€¼
        
        // æƒ…å†µB - å•å˜é‡æ•°å­¦è¿ç®—ï¼š
        "intervention_variable": "å˜é‡å",
        "operation": "add/subtract/multiply/divide",
        "operand": æ•°å€¼
        
        // æƒ…å†µC - å¤šå˜é‡æ•°å­¦è¿ç®—ï¼š
        "interventions": [
            {{"variable": "cement", "operation": "subtract", "operand": 50}},
            {{"variable": "blast_furnace_slag", "operation": "add", "operand": 100}}
        ]
        
        // æƒ…å†µD - å¤šå˜é‡ç»å¯¹å€¼ï¼š
        "intervention_variable": {{"water": 150, "cement": 300}}
    }}
}}

ç¤ºä¾‹1ï¼ˆç»å¯¹å€¼ï¼‰ï¼š
ç”¨æˆ·é—®ï¼š"å¦‚æœæ°´ç”¨é‡ä»200é™åˆ°150ï¼Œå¼ºåº¦ä¼šæ€æ ·ï¼Ÿ"
å›å¤ï¼š{{"intervention_variable": "water", "original_value": 200, "intervention_value": 150}}

ç¤ºä¾‹2ï¼ˆå•å˜é‡è¿ç®—ï¼‰ï¼š
ç”¨æˆ·é—®ï¼š"å¦‚æœæ°´æ³¥å¢åŠ 50 kg/mÂ³ï¼Œå¼ºåº¦ä¼šæ€æ ·ï¼Ÿ"
å›å¤ï¼š{{"intervention_variable": "cement", "operation": "add", "operand": 50}}

ç¤ºä¾‹3ï¼ˆå¤šå˜é‡è¿ç®—ï¼‰ï¼š
ç”¨æˆ·é—®ï¼š"æ·»åŠ çŸ¿æ¸£100 kg/mÂ³ï¼Œå‡å°‘æ°´æ³¥50 kg/mÂ³ï¼Œå¼ºåº¦ä¼šæ€æ ·ï¼Ÿ"
å›å¤ï¼š{{"interventions": [{{"variable": "blast_furnace_slag", "operation": "add", "operand": 100}}, {{"variable": "cement", "operation": "subtract", "operand": 50}}]}}

ç¤ºä¾‹4ï¼ˆå¤šå˜é‡ç»å¯¹å€¼ï¼‰ï¼š
ç”¨æˆ·é—®ï¼š"å¦‚æœæ°´æ³¥300ã€æ°´180ã€é¾„æœŸ28å¤©ï¼Œå¼ºåº¦æ˜¯å¤šå°‘ï¼Ÿ"
å›å¤ï¼š{{"intervention_variable": {{"cement": 300, "water": 180, "age": 28}}}}

ç¤ºä¾‹5ï¼ˆç›®æ ‡å¯¼å‘ - ç™¾åˆ†æ¯”ï¼‰ï¼š
ç”¨æˆ·é—®ï¼š"å¦‚æœæˆ‘æƒ³å¼ºåº¦æå‡10%ï¼Œåº”è¯¥å¦‚ä½•è°ƒæ•´é…åˆæ¯”ï¼Ÿ"
å›å¤ï¼š{{"analysis_type": "intervention", "target_improvement": 10, "specified_variables": []}}

ç¤ºä¾‹6ï¼ˆç›®æ ‡å¯¼å‘ - ç»å¯¹å€¼ï¼‰ï¼š
ç”¨æˆ·é—®ï¼š"ç°åœ¨æˆ‘æƒ³å¼ºåº¦è¾¾åˆ°45ï¼Œæ°´æ³¥å’Œç²‰ç…¤ç°åº”è¯¥æ€ä¹ˆè°ƒï¼Ÿ"
å›å¤ï¼š{{"analysis_type": "intervention", "target_value": 45, "specified_variables": ["cement", "fly_ash"]}}

ç¤ºä¾‹7ï¼ˆç›®æ ‡å¯¼å‘ - æŒ‡å®šå˜é‡ï¼‰ï¼š
ç”¨æˆ·é—®ï¼š"å¦‚ä½•é€šè¿‡è°ƒæ•´æ°´å’Œå‡æ°´å‰‚ä½¿å¼ºåº¦è¾¾åˆ°50 MPaï¼Ÿ"
å›å¤ï¼š{{"analysis_type": "intervention", "target_value": 50, "specified_variables": ["water", "superplasticizer"]}}

ã€å…³é”®ã€‘è¿ç®—ç±»å‹æ˜ å°„ï¼š
- "å¢åŠ "/"æ·»åŠ "/"åŠ " â†’ "add"
- "å‡å°‘"/"é™ä½"/"å‡" â†’ "subtract"
- "ä¹˜ä»¥"/"ç¿»å€" â†’ "multiply"
- "é™¤ä»¥"/"å‡åŠ" â†’ "divide"
"""
    
    response = llm.invoke(prompt)
    
    # è§£æ LLM å“åº”
    import json
    try:
        # æå–JSONå†…å®¹
        content = response.content
        if "```json" in content:
            content = content.split("```json")[1].split("```")[0].strip()
        elif "```" in content:
            content = content.split("```")[1].split("```")[0].strip()
            
        parsed = json.loads(content)
        
        print(f"\nğŸ“‹ åˆ†æç±»å‹: {parsed['analysis_type']}")
        print(f"ğŸ¯ ç›®æ ‡å˜é‡: {parsed['target_variable']}")
        print(f"ğŸ’¡ æ¨ç†: {parsed['reasoning']}")
        
        # ä¼˜å…ˆä½¿ç”¨APIä¼ å…¥çš„å‚æ•°ï¼Œå¦åˆ™ä½¿ç”¨LLMè§£æçš„ç»“æœ
        final_target_value = api_target_value if api_target_value is not None else parsed.get('target_value')
        final_specified_variables = api_specified_variables if api_specified_variables else parsed.get('specified_variables', [])
        
        if parsed.get('target_improvement'):
            print(f"ğŸ¯ ç›®æ ‡æå‡: {parsed['target_improvement']}%")
        if final_target_value:
            print(f"ğŸ¯ ç›®æ ‡å€¼: {final_target_value}")
        if final_specified_variables:
            print(f"ğŸ”§ æŒ‡å®šè°ƒæ•´å˜é‡: {', '.join(final_specified_variables)}")
        
        return {
            "analysis_type": parsed['analysis_type'],
            "target_variable": parsed['target_variable'],
            "routing_reasoning": parsed['reasoning'],
            "intervention_params": parsed.get('extracted_info', {}),
            "target_improvement": parsed.get('target_improvement'),
            "target_value": final_target_value,
            "specified_variables": final_specified_variables
        }
        
    except Exception as e:
        print(f"âš ï¸ è·¯ç”±è§£æå¤±è´¥: {e}")
        # é»˜è®¤ä½¿ç”¨å¹²é¢„åˆ†æï¼Œå¹¶ä½¿ç”¨APIä¼ å…¥çš„å‚æ•°ï¼ˆå¦‚æœæœ‰ï¼‰
        return {
            "analysis_type": "intervention",
            "target_variable": "concrete_compressive_strength",
            "routing_reasoning": "ä½¿ç”¨é»˜è®¤é…ç½®",
            "intervention_params": {},
            "target_value": api_target_value,
            "specified_variables": api_specified_variables if api_specified_variables else []
        }


def causal_analyst_agent(state: CausalAnalysisState) -> dict:
    """
    Causal Analyst Agentï¼šæ‰§è¡Œå› æœåˆ†æ
    
    èŒè´£ï¼š
    1. æ ¹æ® Router çš„æŒ‡ç¤ºè°ƒç”¨å¯¹åº”çš„å› æœåˆ†æå·¥å…·
    2. æ‰§è¡Œè®¡ç®—å¹¶è¿”å›å®šé‡ç»“æœ
    """
    print("\nğŸ“Š Causal Analyst Agent æ­£åœ¨æ‰§è¡Œå› æœåˆ†æ...")
    
    analysis_type = state['analysis_type']
    target_variable = state['target_variable']
    
    try:
        if analysis_type == 'attribution':
            print("æ‰§è¡Œå½’å› åˆ†æ...")
            # é»˜è®¤å¯¹æ¯”å‰300æ¡å’Œå300æ¡æ•°æ®ï¼ˆçœŸå®æ•°æ®å…±1030æ¡ï¼‰
            result = attribution_analysis_tool.invoke({
                "target_variable": target_variable,
                "old_period_start": 0,
                "old_period_end": 300,
                "new_period_start": 700,
                "new_period_end": 1000
            })
            
        elif analysis_type == 'intervention':
            print("æ‰§è¡Œå¹²é¢„åˆ†æ...")
            result = intervention_analysis_tool.invoke({
                "target_variable": target_variable,
                "step_size": 1.0
            })
            
        elif analysis_type == 'counterfactual':
            print("æ‰§è¡Œåäº‹å®åˆ†æ...")
            params = state.get('intervention_params', {})
            
            # ä» Router æå–çš„å‚æ•°ä¸­è·å–å¹²é¢„ä¿¡æ¯
            intervention_variable = params.get('intervention_variable')
            intervention_value = params.get('intervention_value')
            original_value = params.get('original_value')
            operation = params.get('operation')  # æ–°å¢ï¼šæ•°å­¦è¿ç®—
            operand = params.get('operand')  # æ–°å¢ï¼šæ“ä½œæ•°
            interventions_list = params.get('interventions')  # æ–°å¢ï¼šå¤šå˜é‡è¿ç®—åˆ—è¡¨
            
            # è·å–åŸºå‡†é…æ¯”
            def get_base_config():
                if state.get('observed_config') is not None:
                    return state['observed_config']
                elif state.get('reference_sample_index') is not None:
                    idx = state['reference_sample_index']
                    df = _causal_model_instance.df
                    # éªŒè¯ç´¢å¼•æ˜¯å¦åœ¨èŒƒå›´å†…
                    if idx < 0 or idx >= len(df):
                        print(f"  âš ï¸  å‚è€ƒç´¢å¼• {idx} è¶…å‡ºèŒƒå›´ [0, {len(df)-1}]ï¼Œä½¿ç”¨é»˜è®¤ä¸­ä½æ•°æ ·æœ¬")
                        median_idx = (df['concrete_compressive_strength'] - df['concrete_compressive_strength'].median()).abs().idxmin()
                        return df.iloc[median_idx].to_dict()
                    return df.iloc[idx].to_dict()
                else:
                    # ä½¿ç”¨æ•°æ®é›†ä¸­ä½æ•°æ ·æœ¬
                    df = _causal_model_instance.df
                    median_idx = (df['concrete_compressive_strength'] - df['concrete_compressive_strength'].median()).abs().idxmin()
                    return df.iloc[median_idx].to_dict()
            
            base_config = get_base_config()
            
            # æ„å»ºå¹²é¢„å­—å…¸
            interventions = {}
            
            # æƒ…å†µ1ï¼šå¤šå˜é‡æ•°å­¦è¿ç®—ï¼ˆæœ€å¸¸è§çš„å¤æ‚æƒ…å†µï¼‰
            if interventions_list is not None and isinstance(interventions_list, list):
                print(f"\n  ğŸ§® ä½¿ç”¨æ•°å­¦è®¡ç®—å·¥å…·å¤„ç†å¤šå˜é‡è¿ç®—:")
                for item in interventions_list:
                    var = item.get('variable')
                    op = item.get('operation')
                    val = item.get('operand')
                    
                    if var and op and val is not None:
                        base_val = float(base_config.get(var, 0))
                        # ä½¿ç”¨æ•°å­¦è®¡ç®—å·¥å…·
                        new_val = math_calculator_tool.invoke({
                            'variable': var,
                            'base_value': base_val,
                            'operation': op,
                            'operand': val
                        })
                        interventions[var] = new_val
            
            # æƒ…å†µ2ï¼šå•å˜é‡æ•°å­¦è¿ç®—
            elif isinstance(intervention_variable, str) and operation is not None and operand is not None:
                print(f"\n  ğŸ§® ä½¿ç”¨æ•°å­¦è®¡ç®—å·¥å…·å¤„ç†å•å˜é‡è¿ç®—:")
                base_value = float(base_config.get(intervention_variable, 0))
                new_value = math_calculator_tool.invoke({
                    'variable': intervention_variable,
                    'base_value': base_value,
                    'operation': operation,
                    'operand': operand
                })
                interventions[intervention_variable] = new_value
                original_value = base_value
            
            # æƒ…å†µ3ï¼šå•ä¸ªå˜é‡çš„ç»å¯¹å€¼å¹²é¢„
            elif isinstance(intervention_variable, str) and intervention_value is not None:
                interventions[intervention_variable] = intervention_value
                print(f"  ğŸ“Š ç»å¯¹å€¼å¹²é¢„: {intervention_variable} = {intervention_value}")
            
            # æƒ…å†µ4ï¼šå¤šå˜é‡ç»å¯¹å€¼å¹²é¢„ï¼ˆå­—å…¸å½¢å¼ï¼‰
            elif isinstance(intervention_variable, dict):
                interventions = intervention_variable
                print(f"  ğŸ“Š å¤šå˜é‡ç»å¯¹å€¼å¹²é¢„: {interventions}")
            elif isinstance(intervention_value, dict):
                interventions = intervention_value
                print(f"  ğŸ“Š å¤šå˜é‡ç»å¯¹å€¼å¹²é¢„: {interventions}")
            
            # æƒ…å†µ5ï¼šæ²¡æœ‰æå–åˆ°å¹²é¢„ä¿¡æ¯ï¼Œä½¿ç”¨é»˜è®¤
            if not interventions:
                interventions = {'water': 150}  # é»˜è®¤é™ä½ç”¨æ°´é‡
                print(f"  âš ï¸  æœªæå–åˆ°å¹²é¢„ä¿¡æ¯ï¼Œä½¿ç”¨é»˜è®¤å¹²é¢„: {interventions}")
            
            # é€‰æ‹©è§‚æµ‹æ•°æ®çš„æ¥æº
            # ä¼˜å…ˆçº§: observed_config > reference_sample_index > è‡ªåŠ¨åŒ¹é… > é»˜è®¤æ ·æœ¬
            
            if state.get('observed_config') is not None:
                # ç”¨æˆ·ç›´æ¥è¾“å…¥äº†è§‚æµ‹é…æ¯”
                print(f"  âœ… ä½¿ç”¨ç”¨æˆ·è¾“å…¥çš„è§‚æµ‹é…æ¯”")
                
                # å¦‚æœobserved_configä¸­ç¼ºå°‘concrete_compressive_strengthï¼Œå…ˆç”¨å› æœæ¨¡å‹é¢„æµ‹
                observed_config_full = state['observed_config'].copy()
                if 'concrete_compressive_strength' not in observed_config_full:
                    print(f"  ğŸ”® é¢„æµ‹åŸºå‡†å¼ºåº¦...")
                    from dowhy import gcm
                    
                    # ä½¿ç”¨å› æœæ¨¡å‹é¢„æµ‹åŸºå‡†å¼ºåº¦
                    intervention_funcs = {
                        'cement': lambda x: observed_config_full.get('cement', 280),
                        'blast_furnace_slag': lambda x: observed_config_full.get('blast_furnace_slag', 0),
                        'fly_ash': lambda x: observed_config_full.get('fly_ash', 0),
                        'water': lambda x: observed_config_full.get('water', 180),
                        'superplasticizer': lambda x: observed_config_full.get('superplasticizer', 0),
                        'coarse_aggregate': lambda x: observed_config_full.get('coarse_aggregate', 1000),
                        'fine_aggregate': lambda x: observed_config_full.get('fine_aggregate', 800),
                        'age': lambda x: observed_config_full.get('age', 28)
                    }
                    samples = gcm.interventional_samples(
                        _causal_model_instance.causal_model,
                        intervention_funcs,
                        num_samples_to_draw=100
                    )
                    predicted_strength = float(samples['concrete_compressive_strength'].mean())
                    observed_config_full['concrete_compressive_strength'] = predicted_strength
                    print(f"  âœ“ åŸºå‡†å¼ºåº¦: {predicted_strength:.2f} MPa")
                
                observed_data_df = pd.DataFrame([observed_config_full])
                
                # ç›´æ¥ä½¿ç”¨counterfactual_analysis
                result_dict = _causal_model_instance.counterfactual_analysis(
                    observed_data=observed_data_df,
                    interventions=interventions,
                    target=target_variable,
                    num_samples=1000
                )
                
                # æ„å»ºç»“æœ
                result = {
                    "type": "counterfactual",
                    "sample_index": "ç”¨æˆ·è¾“å…¥",
                    "target": target_variable,
                    "interventions": [{
                        "variable": var,
                        "original_value": float(observed_config_full.get(var, 0)),
                        "new_value": float(new_val)
                    } for var, new_val in interventions.items()],
                    "observed_mean": float(result_dict['observed_mean']),
                    "counterfactual_mean": float(result_dict['counterfactual_mean']),
                    "causal_effect": float(result_dict['causal_effect'])
                }
                
            else:
                # ä½¿ç”¨æ ·æœ¬ç´¢å¼•
                df = _causal_model_instance.df
                if state.get('reference_sample_index') is not None:
                    sample_index = state['reference_sample_index']
                    # éªŒè¯ç´¢å¼•æ˜¯å¦åœ¨èŒƒå›´å†…
                    if sample_index < 0 or sample_index >= len(df):
                        print(f"  âš ï¸  å‚è€ƒç´¢å¼• {sample_index} è¶…å‡ºèŒƒå›´ [0, {len(df)-1}]ï¼Œä½¿ç”¨é»˜è®¤æ ·æœ¬")
                        sample_index = min(100, len(df) - 1)  # ä½¿ç”¨é»˜è®¤æ ·æœ¬ï¼Œç¡®ä¿ä¸è¶…å‡ºèŒƒå›´
                        
                        # æ˜¾ç¤ºé»˜è®¤æ ·æœ¬çš„å®Œæ•´ä¿¡æ¯
                        sample = df.iloc[sample_index]
                        print(f"\n  ğŸ“‹ é»˜è®¤åŸºå‡†æ ·æœ¬è¯¦æƒ…:")
                        print(f"    â€¢ æ°´æ³¥: {sample['cement']:.1f} kg/mÂ³")
                        print(f"    â€¢ é«˜ç‚‰çŸ¿æ¸£: {sample['blast_furnace_slag']:.1f} kg/mÂ³")
                        print(f"    â€¢ ç²‰ç…¤ç°: {sample['fly_ash']:.1f} kg/mÂ³")
                        print(f"    â€¢ æ°´: {sample['water']:.1f} kg/mÂ³")
                        print(f"    â€¢ å‡æ°´å‰‚: {sample['superplasticizer']:.1f} kg/mÂ³")
                        print(f"    â€¢ ç²—éª¨æ–™: {sample['coarse_aggregate']:.1f} kg/mÂ³")
                        print(f"    â€¢ ç»†éª¨æ–™: {sample['fine_aggregate']:.1f} kg/mÂ³")
                        print(f"    â€¢ é¾„æœŸ: {sample['age']:.0f} å¤©")
                        print(f"    â€¢ åŸå§‹å¼ºåº¦: {sample['concrete_compressive_strength']:.2f} MPa")
                        
                        # ä¿å­˜åŸºå‡†æ ·æœ¬ä¿¡æ¯åˆ°state
                        state['base_sample_info'] = build_sample_info_dict(sample, source="é»˜è®¤æ ·æœ¬ï¼ˆç´¢å¼•{}ï¼‰".format(sample_index))
                    else:
                        print(f"  ä½¿ç”¨ç”¨æˆ·é€‰æ‹©çš„å‚è€ƒæ‰¹æ¬¡: ç´¢å¼• {sample_index}")
                        
                        # æ˜¾ç¤ºå‚è€ƒæ ·æœ¬çš„å®Œæ•´ä¿¡æ¯
                        sample = df.iloc[sample_index]
                        print(f"\n  ğŸ“‹ å‚è€ƒæ ·æœ¬è¯¦æƒ…:")
                        print(f"    â€¢ æ°´æ³¥: {sample['cement']:.1f} kg/mÂ³")
                        print(f"    â€¢ é«˜ç‚‰çŸ¿æ¸£: {sample['blast_furnace_slag']:.1f} kg/mÂ³")
                        print(f"    â€¢ ç²‰ç…¤ç°: {sample['fly_ash']:.1f} kg/mÂ³")
                        print(f"    â€¢ æ°´: {sample['water']:.1f} kg/mÂ³")
                        print(f"    â€¢ å‡æ°´å‰‚: {sample['superplasticizer']:.1f} kg/mÂ³")
                        print(f"    â€¢ ç²—éª¨æ–™: {sample['coarse_aggregate']:.1f} kg/mÂ³")
                        print(f"    â€¢ ç»†éª¨æ–™: {sample['fine_aggregate']:.1f} kg/mÂ³")
                        print(f"    â€¢ é¾„æœŸ: {sample['age']:.0f} å¤©")
                        print(f"    â€¢ åŸå§‹å¼ºåº¦: {sample['concrete_compressive_strength']:.2f} MPa")
                        
                        # ä¿å­˜åŸºå‡†æ ·æœ¬ä¿¡æ¯åˆ°state
                        state['base_sample_info'] = build_sample_info_dict(sample, source="ç”¨æˆ·æŒ‡å®šæ ·æœ¬ï¼ˆç´¢å¼•{}ï¼‰".format(sample_index))
                # å¦‚æœæå–åˆ°äº†åŸå§‹å€¼ï¼Œå°è¯•æ‰¾åˆ°æ¥è¿‘è¯¥å€¼çš„æ ·æœ¬
                elif original_value is not None and _causal_model_instance is not None:
                    # ä½¿ç”¨ç¬¬ä¸€ä¸ªå¹²é¢„å˜é‡æ‰¾åˆ°æœ€æ¥è¿‘çš„æ ·æœ¬
                    first_var = list(interventions.keys())[0]
                    if first_var in df.columns:
                        closest_idx = (df[first_var] - original_value).abs().idxmin()
                        sample_index = int(closest_idx)
                        print(f"  æ‰¾åˆ°æœ€æ¥è¿‘åŸå§‹å€¼ {original_value} çš„æ ·æœ¬: ç´¢å¼• {sample_index}")
                        
                        # æ˜¾ç¤ºæ‰¾åˆ°çš„æ ·æœ¬çš„å®Œæ•´ä¿¡æ¯
                        sample = df.iloc[sample_index]
                        print(f"\n  ğŸ“‹ åŸºå‡†æ ·æœ¬è¯¦æƒ…:")
                        print(f"    â€¢ æ°´æ³¥: {sample['cement']:.1f} kg/mÂ³")
                        print(f"    â€¢ é«˜ç‚‰çŸ¿æ¸£: {sample['blast_furnace_slag']:.1f} kg/mÂ³")
                        print(f"    â€¢ ç²‰ç…¤ç°: {sample['fly_ash']:.1f} kg/mÂ³")
                        print(f"    â€¢ æ°´: {sample['water']:.1f} kg/mÂ³")
                        print(f"    â€¢ å‡æ°´å‰‚: {sample['superplasticizer']:.1f} kg/mÂ³")
                        print(f"    â€¢ ç²—éª¨æ–™: {sample['coarse_aggregate']:.1f} kg/mÂ³")
                        print(f"    â€¢ ç»†éª¨æ–™: {sample['fine_aggregate']:.1f} kg/mÂ³")
                        print(f"    â€¢ é¾„æœŸ: {sample['age']:.0f} å¤©")
                        print(f"    â€¢ åŸå§‹å¼ºåº¦: {sample['concrete_compressive_strength']:.2f} MPa")
                        
                        # ä¿å­˜åŸºå‡†æ ·æœ¬ä¿¡æ¯åˆ°state
                        state['base_sample_info'] = build_sample_info_dict(sample, source="è‡ªåŠ¨åŒ¹é…æ ·æœ¬ï¼ˆç´¢å¼•{}ï¼‰".format(sample_index))
                else:
                    sample_index = min(100, len(df) - 1)  # é»˜è®¤æ ·æœ¬ï¼Œç¡®ä¿ä¸è¶…å‡ºèŒƒå›´
                    print(f"  ä½¿ç”¨é»˜è®¤æ ·æœ¬ç´¢å¼•: {sample_index}")
                    
                    # è·å–å¹¶æ˜¾ç¤ºé»˜è®¤æ ·æœ¬çš„å®Œæ•´ä¿¡æ¯
                    sample = df.iloc[sample_index]
                    print(f"\n  ğŸ“‹ é»˜è®¤åŸºå‡†æ ·æœ¬è¯¦æƒ…:")
                    print(f"    â€¢ æ°´æ³¥: {sample['cement']:.1f} kg/mÂ³")
                    print(f"    â€¢ é«˜ç‚‰çŸ¿æ¸£: {sample['blast_furnace_slag']:.1f} kg/mÂ³")
                    print(f"    â€¢ ç²‰ç…¤ç°: {sample['fly_ash']:.1f} kg/mÂ³")
                    print(f"    â€¢ æ°´: {sample['water']:.1f} kg/mÂ³")
                    print(f"    â€¢ å‡æ°´å‰‚: {sample['superplasticizer']:.1f} kg/mÂ³")
                    print(f"    â€¢ ç²—éª¨æ–™: {sample['coarse_aggregate']:.1f} kg/mÂ³")
                    print(f"    â€¢ ç»†éª¨æ–™: {sample['fine_aggregate']:.1f} kg/mÂ³")
                    print(f"    â€¢ é¾„æœŸ: {sample['age']:.0f} å¤©")
                    print(f"    â€¢ åŸå§‹å¼ºåº¦: {sample['concrete_compressive_strength']:.2f} MPa")
                    
                    # ä¿å­˜åŸºå‡†æ ·æœ¬ä¿¡æ¯åˆ°state
                    state['base_sample_info'] = build_sample_info_dict(sample, source="é»˜è®¤æ ·æœ¬ï¼ˆç´¢å¼•{})".format(sample_index))
                
                print(f"\n  ğŸ”§ å¹²é¢„å˜é‡: {', '.join(interventions.keys())}")
                print(f"  ğŸ¯ å¹²é¢„å€¼: {interventions}")
                
                result = counterfactual_analysis_tool.invoke({
                    "sample_index": sample_index,
                    "interventions": interventions,
                    "target_variable": target_variable
                })
            
        else:
            result = {"error": f"æœªçŸ¥çš„åˆ†æç±»å‹: {analysis_type}"}
        
        if "error" in result:
            print(f"âŒ åˆ†æå¤±è´¥: {result['error']}")
            return {
                "causal_results": result,
                "analysis_summary": f"åˆ†æå¤±è´¥: {result['error']}",
                "error": result['error']
            }
        
        # ç”Ÿæˆç®€è¦æ‘˜è¦
        summary = _generate_analysis_summary(result)
        print(f"\nâœ“ åˆ†æå®Œæˆ")
        print(f"ğŸ“ æ‘˜è¦: {summary[:200]}...")
        
        return {
            "causal_results": result,
            "analysis_summary": summary
        }
        
    except Exception as e:
        print(f"âŒ åˆ†æå¼‚å¸¸: {e}")
        return {
            "causal_results": {"error": str(e)},
            "analysis_summary": f"åˆ†æå¼‚å¸¸: {e}",
            "error": str(e)
        }


def optimizer_agent(state: CausalAnalysisState) -> dict:
    """
    Optimizer Agentï¼šæ ¹æ®å› æœåˆ†æç»“æœï¼Œç”Ÿæˆä¼˜åŒ–é…æ¯”å¹¶é¢„æµ‹å¼ºåº¦
    
    èŒè´£ï¼š
    1. æ ¹æ®å¹²é¢„åˆ†æç»“æœï¼Œæ‰¾å‡ºæœ€æœ‰æ•ˆçš„è°ƒæ•´å˜é‡
    2. åŸºäºç”¨æˆ·ç›®æ ‡ï¼ˆå¦‚"æå‡10%"ï¼‰ï¼Œè®¡ç®—å…·ä½“é…æ¯”
    3. ä½¿ç”¨å› æœæ¨¡å‹é¢„æµ‹æ–°é…æ¯”çš„å¼ºåº¦
    4. éªŒè¯æ˜¯å¦è¾¾åˆ°ç›®æ ‡
    """
    print("\nğŸ”§ Optimizer Agent æ­£åœ¨ç”Ÿæˆä¼˜åŒ–é…æ¯”...")
    
    # åªå¯¹å¹²é¢„åˆ†æå’Œåäº‹å®åˆ†æéœ€è¦ä¼˜åŒ–é…æ¯”
    analysis_type = state['analysis_type']
    
    if analysis_type not in ['intervention', 'counterfactual']:
        print("  è·³è¿‡ä¼˜åŒ–ï¼ˆä»…å¹²é¢„å’Œåäº‹å®åˆ†æéœ€è¦ï¼‰")
        return {
            "optimized_config": None,
            "predicted_strength": None,
            "optimization_summary": ""
        }
    
    try:
        from dowhy import gcm
        import numpy as np
        
        # è·å–åŸºå‡†é…æ¯”
        if state.get('observed_config'):
            base_config = state['observed_config'].copy()
            print(f"  åŸºå‡†é…æ¯”ï¼šç”¨æˆ·è¾“å…¥")
            
            # å¦‚æœç”¨æˆ·è¾“å…¥çš„é…æ¯”ä¸­æ²¡æœ‰å¼ºåº¦ï¼Œå…ˆé¢„æµ‹ä¸€ä¸ª
            if 'concrete_compressive_strength' not in base_config:
                print(f"  ğŸ”® é¢„æµ‹åŸºå‡†å¼ºåº¦...")
                intervention_funcs = {
                    'cement': lambda x: base_config.get('cement', 280),
                    'blast_furnace_slag': lambda x: base_config.get('blast_furnace_slag', 0),
                    'fly_ash': lambda x: base_config.get('fly_ash', 0),
                    'water': lambda x: base_config.get('water', 180),
                    'superplasticizer': lambda x: base_config.get('superplasticizer', 0),
                    'coarse_aggregate': lambda x: base_config.get('coarse_aggregate', 1000),
                    'fine_aggregate': lambda x: base_config.get('fine_aggregate', 800),
                    'age': lambda x: base_config.get('age', 28)
                }
                samples = gcm.interventional_samples(
                    _causal_model_instance.causal_model,
                    intervention_funcs,
                    num_samples_to_draw=100
                )
                predicted_strength = float(samples['concrete_compressive_strength'].mean())
                base_config['concrete_compressive_strength'] = predicted_strength
                print(f"  âœ“ åŸºå‡†å¼ºåº¦: {predicted_strength:.2f} MPa")
                
        elif state.get('reference_sample_index') is not None:
            idx = state['reference_sample_index']
            df = _causal_model_instance.df
            # éªŒè¯ç´¢å¼•æ˜¯å¦åœ¨èŒƒå›´å†…
            if idx < 0 or idx >= len(df):
                print(f"  âš ï¸  å‚è€ƒç´¢å¼• {idx} è¶…å‡ºèŒƒå›´ [0, {len(df)-1}]ï¼Œä½¿ç”¨é»˜è®¤ä¸­ç­‰å¼ºåº¦æ ·æœ¬")
                df_28d = df[df['age'] == 28]
                if len(df_28d) > 0:
                    median_idx = (df_28d['concrete_compressive_strength'] - df_28d['concrete_compressive_strength'].median()).abs().idxmin()
                    base_config = df.loc[median_idx].to_dict()
                else:
                    median_idx = (df['concrete_compressive_strength'] - df['concrete_compressive_strength'].median()).abs().idxmin()
                    base_config = df.loc[median_idx].to_dict()
                print(f"  åŸºå‡†é…æ¯”ï¼šä¸­ç­‰å¼ºåº¦æ ·æœ¬")
                
                # æ˜¾ç¤ºé»˜è®¤æ ·æœ¬çš„å®Œæ•´ä¿¡æ¯
                print(f"\n  ğŸ“‹ é»˜è®¤åŸºå‡†æ ·æœ¬è¯¦æƒ…:")
                print(f"    â€¢ æ°´æ³¥: {base_config['cement']:.1f} kg/mÂ³")
                print(f"    â€¢ é«˜ç‚‰çŸ¿æ¸£: {base_config['blast_furnace_slag']:.1f} kg/mÂ³")
                print(f"    â€¢ ç²‰ç…¤ç°: {base_config['fly_ash']:.1f} kg/mÂ³")
                print(f"    â€¢ æ°´: {base_config['water']:.1f} kg/mÂ³")
                print(f"    â€¢ å‡æ°´å‰‚: {base_config['superplasticizer']:.1f} kg/mÂ³")
                print(f"    â€¢ ç²—éª¨æ–™: {base_config['coarse_aggregate']:.1f} kg/mÂ³")
                print(f"    â€¢ ç»†éª¨æ–™: {base_config['fine_aggregate']:.1f} kg/mÂ³")
                print(f"    â€¢ é¾„æœŸ: {base_config['age']:.0f} å¤©")
                print(f"    â€¢ åŸå§‹å¼ºåº¦: {base_config['concrete_compressive_strength']:.2f} MPa")
                
                # ä¿å­˜åŸºå‡†æ ·æœ¬ä¿¡æ¯åˆ°state
                state['base_sample_info'] = build_sample_info_dict(pd.Series(base_config), source="é»˜è®¤æ ·æœ¬ï¼ˆä¸­ç­‰å¼ºåº¦ï¼‰")
            else:
                base_config = df.iloc[idx].to_dict()
                print(f"  åŸºå‡†é…æ¯”ï¼šå‚è€ƒæ‰¹æ¬¡#{idx}")
                
                # æ˜¾ç¤ºå‚è€ƒæ ·æœ¬çš„å®Œæ•´ä¿¡æ¯
                print(f"\n  ğŸ“‹ å‚è€ƒæ ·æœ¬è¯¦æƒ…:")
                print(f"    â€¢ æ°´æ³¥: {base_config['cement']:.1f} kg/mÂ³")
                print(f"    â€¢ é«˜ç‚‰çŸ¿æ¸£: {base_config['blast_furnace_slag']:.1f} kg/mÂ³")
                print(f"    â€¢ ç²‰ç…¤ç°: {base_config['fly_ash']:.1f} kg/mÂ³")
                print(f"    â€¢ æ°´: {base_config['water']:.1f} kg/mÂ³")
                print(f"    â€¢ å‡æ°´å‰‚: {base_config['superplasticizer']:.1f} kg/mÂ³")
                print(f"    â€¢ ç²—éª¨æ–™: {base_config['coarse_aggregate']:.1f} kg/mÂ³")
                print(f"    â€¢ ç»†éª¨æ–™: {base_config['fine_aggregate']:.1f} kg/mÂ³")
                print(f"    â€¢ é¾„æœŸ: {base_config['age']:.0f} å¤©")
                print(f"    â€¢ åŸå§‹å¼ºåº¦: {base_config['concrete_compressive_strength']:.2f} MPa")
                
                # ä¿å­˜åŸºå‡†æ ·æœ¬ä¿¡æ¯åˆ°state
                state['base_sample_info'] = build_sample_info_dict(pd.Series(base_config), source="ç”¨æˆ·æŒ‡å®šæ ·æœ¬ï¼ˆç´¢å¼•{}ï¼‰".format(idx))
        else:
            # æ²¡æœ‰æä¾›åŸºå‡†é…æ¯”æˆ–å‚è€ƒç´¢å¼•
            # æ£€æŸ¥æ˜¯å¦æœ‰æ˜ç¡®çš„ç›®æ ‡å€¼æˆ–ç›®æ ‡æå‡
            target_value = state.get('target_value')
            target_improvement = state.get('target_improvement')
            
            # å¦‚æœæ²¡æœ‰æ˜ç¡®ç›®æ ‡ï¼Œè¯´æ˜æ˜¯çº¯æ¢ç´¢æ€§é—®é¢˜ï¼Œä¸è¿›è¡Œä¼˜åŒ–
            if target_value is None and target_improvement is None:
                print(f"  â„¹ï¸  æœªæä¾›åŸºå‡†é…æ¯”æˆ–å‚è€ƒç´¢å¼•ï¼Œä¸”æ— æ˜ç¡®ä¼˜åŒ–ç›®æ ‡")
                print(f"  â†’ è¿™æ˜¯ä¸€ä¸ªæ¢ç´¢æ€§é—®é¢˜ï¼Œåªè¿”å›å› ç´ åˆ†æç»“æœ")
                print(f"  ï¼ˆå¦‚éœ€å…·ä½“ä¼˜åŒ–é…æ¯”ï¼Œè¯·æä¾›åŸºå‡†é…æ¯”æˆ–å‚è€ƒç´¢å¼•ï¼‰")
                return {
                    "optimized_config": None,
                    "predicted_strength": None,
                    "optimization_summary": ""
                }
            
            # å¦‚æœæœ‰æ˜ç¡®ç›®æ ‡ï¼Œä½¿ç”¨é»˜è®¤ä¸­ç­‰å¼ºåº¦æ ·æœ¬ä½œä¸ºåŸºå‡†
            df = _causal_model_instance.df
            df_28d = df[df['age'] == 28]
            if len(df_28d) > 0:
                median_idx = (df_28d['concrete_compressive_strength'] - df_28d['concrete_compressive_strength'].median()).abs().idxmin()
                base_config = df.loc[median_idx].to_dict()
            else:
                median_idx = (df['concrete_compressive_strength'] - df['concrete_compressive_strength'].median()).abs().idxmin()
                base_config = df.loc[median_idx].to_dict()
            
            print(f"  åŸºå‡†é…æ¯”ï¼šé»˜è®¤ä¸­ç­‰å¼ºåº¦æ ·æœ¬ï¼ˆå› æä¾›äº†æ˜ç¡®ç›®æ ‡ï¼‰")
            print(f"\n  ğŸ“‹ é»˜è®¤åŸºå‡†æ ·æœ¬è¯¦æƒ…:")
            print(f"    â€¢ æ°´æ³¥: {base_config['cement']:.1f} kg/mÂ³")
            print(f"    â€¢ é«˜ç‚‰çŸ¿æ¸£: {base_config['blast_furnace_slag']:.1f} kg/mÂ³")
            print(f"    â€¢ ç²‰ç…¤ç°: {base_config['fly_ash']:.1f} kg/mÂ³")
            print(f"    â€¢ æ°´: {base_config['water']:.1f} kg/mÂ³")
            print(f"    â€¢ å‡æ°´å‰‚: {base_config['superplasticizer']:.1f} kg/mÂ³")
            print(f"    â€¢ ç²—éª¨æ–™: {base_config['coarse_aggregate']:.1f} kg/mÂ³")
            print(f"    â€¢ ç»†éª¨æ–™: {base_config['fine_aggregate']:.1f} kg/mÂ³")
            print(f"    â€¢ é¾„æœŸ: {base_config['age']:.0f} å¤©")
            print(f"    â€¢ åŸå§‹å¼ºåº¦: {base_config['concrete_compressive_strength']:.2f} MPa")
            
            # ä¿å­˜åŸºå‡†æ ·æœ¬ä¿¡æ¯åˆ°state
            state['base_sample_info'] = build_sample_info_dict(pd.Series(base_config), source="é»˜è®¤æ ·æœ¬ï¼ˆä¸­ç­‰å¼ºåº¦ï¼‰")
        
        # æå–å½“å‰å¼ºåº¦å’Œç›®æ ‡æå‡
        base_strength = base_config.get('concrete_compressive_strength', 35.0)
        # target_improvement å·²åœ¨å‰é¢è·å–ï¼Œè¿™é‡Œç›´æ¥ä½¿ç”¨ state
        target_improvement = state.get('target_improvement')  # ç™¾åˆ†æ¯”ï¼Œå¦‚10è¡¨ç¤ºæå‡10%
        
        # ä»å¹²é¢„åˆ†æç»“æœè·å–æœ€æœ‰æ•ˆçš„å˜é‡
        causal_results = state.get('causal_results', {})
        
        # ç”Ÿæˆä¼˜åŒ–é…æ¯”
        optimized_config = base_config.copy()
        
        if analysis_type == 'intervention' and 'interventions' in causal_results:
            # åŸºäºå¹²é¢„åˆ†æç»“æœä¼˜åŒ–
            interventions = causal_results['interventions']
            
            # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦æŒ‡å®šäº†è¦è°ƒæ•´çš„å˜é‡
            specified_vars = state.get('specified_variables', [])
            
            if specified_vars:
                # ç”¨æˆ·æŒ‡å®šäº†å˜é‡ï¼Œåªä½¿ç”¨è¿™äº›å˜é‡
                print(f"\n  ğŸ”§ ä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„å˜é‡: {', '.join(specified_vars)}")
                top_interventions = [
                    i for i in interventions 
                    if i['variable'] in specified_vars
                ]
                
                # æŒ‰æ•ˆåº”å¤§å°æ’åº
                top_interventions = sorted(top_interventions, 
                                          key=lambda x: abs(x['causal_effect']), 
                                          reverse=True)
                
                if not top_interventions:
                    print(f"  âš ï¸  æŒ‡å®šçš„å˜é‡æœªåœ¨å¹²é¢„åˆ†æç»“æœä¸­æ‰¾åˆ°ï¼Œå°†ä½¿ç”¨Top 3")
                    # å›é€€åˆ°Top 3
                    significant_interventions = [
                        i for i in interventions 
                        if i['confidence_interval'][0] * i['confidence_interval'][1] > 0
                    ]
                    top_interventions = sorted(significant_interventions, 
                                              key=lambda x: abs(x['causal_effect']), 
                                              reverse=True)[:3]
                    
                    if not top_interventions:
                        top_interventions = sorted(interventions, 
                                                  key=lambda x: abs(x['causal_effect']), 
                                                  reverse=True)[:3]
            else:
                # ç”¨æˆ·æœªæŒ‡å®šå˜é‡ï¼Œè‡ªåŠ¨é€‰æ‹©Top 3æœ€æœ‰æ•ˆçš„å˜é‡
                significant_interventions = [
                    i for i in interventions 
                    if i['confidence_interval'][0] * i['confidence_interval'][1] > 0  # åŒå·è¯´æ˜æ˜¾è‘—
                ]
                top_interventions = sorted(significant_interventions, 
                                          key=lambda x: abs(x['causal_effect']), 
                                          reverse=True)[:3]
                
                if not top_interventions:
                    # å¦‚æœæ²¡æœ‰æ˜¾è‘—å˜é‡ï¼Œä½¿ç”¨ç»å¯¹æ•ˆåº”æœ€å¤§çš„å‰3ä¸ª
                    top_interventions = sorted(interventions, 
                                              key=lambda x: abs(x['causal_effect']), 
                                              reverse=True)[:3]
            
            print(f"\n  Top {len(top_interventions)} æœ‰æ•ˆå˜é‡:")
            for interv in top_interventions:
                print(f"    â€¢ {interv['variable']}: æ•ˆåº”={interv['causal_effect']:+.4f}")
            
            # å¦‚æœç”¨æˆ·æŒ‡å®šäº†ç›®æ ‡å€¼æˆ–ç›®æ ‡æå‡ï¼Œä½¿ç”¨ç²¾ç¡®ä¼˜åŒ–
            target_value = state.get('target_value')
            
            if target_value is not None:
                # ç”¨æˆ·æŒ‡å®šäº†ç»å¯¹ç›®æ ‡å€¼
                print(f"\n  ğŸ¯ ç›®æ ‡ï¼šå¼ºåº¦è¾¾åˆ° {target_value} MPa")
                print(f"  ä½¿ç”¨è¿­ä»£ä¼˜åŒ–ç®—æ³•å¯»æ‰¾æœ€ä¼˜é…æ¯”...")
                target_strength = float(target_value)
            elif target_improvement is not None and target_improvement != 0:
                # ç”¨æˆ·æŒ‡å®šäº†ç›¸å¯¹æå‡ç™¾åˆ†æ¯”
                print(f"\n  ğŸ¯ ç›®æ ‡ï¼šæå‡ {target_improvement}%")
                print(f"  ä½¿ç”¨è¿­ä»£ä¼˜åŒ–ç®—æ³•å¯»æ‰¾æœ€ä¼˜é…æ¯”...")
                target_strength = base_strength * (1 + target_improvement / 100.0)
            else:
                target_strength = None
            
            if target_strength is not None:
                
                # å®šä¹‰é¢„æµ‹å‡½æ•°
                def predict_strength(config):
                    """ç»™å®šé…æ¯”ï¼Œé¢„æµ‹å¼ºåº¦"""
                    intervention_funcs = {
                        'cement': lambda x: config.get('cement', 280),
                        'blast_furnace_slag': lambda x: config.get('blast_furnace_slag', 0),
                        'fly_ash': lambda x: config.get('fly_ash', 0),
                        'water': lambda x: config.get('water', 180),
                        'superplasticizer': lambda x: config.get('superplasticizer', 0),
                        'coarse_aggregate': lambda x: config.get('coarse_aggregate', 1000),
                        'fine_aggregate': lambda x: config.get('fine_aggregate', 800),
                        'age': lambda x: config.get('age', 28)
                    }
                    samples = gcm.interventional_samples(
                        _causal_model_instance.causal_model,
                        intervention_funcs,
                        num_samples_to_draw=100
                    )
                    return float(samples['concrete_compressive_strength'].mean())
                
                # ä½¿ç”¨äºŒåˆ†æœç´¢æ‰¾åˆ°åˆé€‚çš„è°ƒæ•´æ¯”ä¾‹
                best_scale = 1.0
                best_config = base_config.copy()
                best_strength = base_strength
                best_diff = abs(base_strength - target_strength)
                
                # äºŒåˆ†æœç´¢èŒƒå›´
                low_scale = 0.0
                high_scale = 0.5  # æœ€å¤šè°ƒæ•´50%
                
                max_iterations = 8
                tolerance = target_strength * 0.02  # å…è®¸2%çš„è¯¯å·®
                
                for iteration in range(max_iterations):
                    mid_scale = (low_scale + high_scale) / 2.0
                    
                    # åº”ç”¨è°ƒæ•´
                    test_config = base_config.copy()
                    for interv in top_interventions:
                        var = interv['variable']
                        effect = interv['causal_effect']
                        if var in test_config:
                            current_val = base_config[var]
                            # æ­£æ•ˆåº”å¢åŠ ï¼Œè´Ÿæ•ˆåº”å‡å°‘
                            if effect > 0:
                                test_config[var] = current_val * (1 + mid_scale)
                            else:
                                test_config[var] = current_val * (1 - mid_scale)
                    
                    # é¢„æµ‹å¼ºåº¦
                    pred_strength = predict_strength(test_config)
                    diff = pred_strength - target_strength
                    
                    print(f"    è¿­ä»£ {iteration+1}: scale={mid_scale:.3f}, é¢„æµ‹={pred_strength:.2f} MPa, å·®è·={diff:+.2f} MPa")
                    
                    # æ›´æ–°æœ€ä¼˜è§£
                    if abs(diff) < best_diff:
                        best_diff = abs(diff)
                        best_scale = mid_scale
                        best_config = test_config.copy()
                        best_strength = pred_strength
                    
                    # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°ç›®æ ‡
                    if abs(diff) < tolerance:
                        print(f"    âœ“ å·²è¾¾åˆ°ç›®æ ‡ï¼ˆè¯¯å·® < {tolerance:.2f} MPaï¼‰")
                        break
                    
                    # è°ƒæ•´æœç´¢èŒƒå›´
                    if diff < 0:
                        # é¢„æµ‹å¼ºåº¦ä¸å¤Ÿï¼Œéœ€è¦æ›´å¤§çš„è°ƒæ•´
                        low_scale = mid_scale
                    else:
                        # é¢„æµ‹å¼ºåº¦è¿‡é«˜ï¼Œå‡å°è°ƒæ•´
                        high_scale = mid_scale
                
                optimized_config = best_config
                predicted_strength = best_strength
                
                print(f"\n  âœ“ æœ€ä¼˜è°ƒæ•´æ¯”ä¾‹: {best_scale:.1%}")
                print(f"  âœ“ é…æ¯”è°ƒæ•´è¯¦æƒ…:")
                for interv in top_interventions:
                    var = interv['variable']
                    if var in optimized_config:
                        old_val = base_config[var]
                        new_val = optimized_config[var]
                        if old_val != 0:
                            change_pct = ((new_val - old_val) / old_val) * 100
                            print(f"    â€¢ {var}: {old_val:.1f} â†’ {new_val:.1f} ({change_pct:+.1f}%)")
                        else:
                            change = new_val - old_val
                            print(f"    â€¢ {var}: {old_val:.1f} â†’ {new_val:.1f} ({change:+.1f} kg/mÂ³)")
            
            else:
                # æ²¡æœ‰æŒ‡å®šç›®æ ‡ - æ£€æŸ¥ç”¨æˆ·æ„å›¾
                user_query = state.get('user_query', '').lower()
                is_pure_prediction = any(keyword in user_query for keyword in ['é¢„æµ‹', 'é¢„æŠ¥', 'å¼ºåº¦æ˜¯å¤šå°‘', 'å¤šå°‘mpa', 'èƒ½è¾¾åˆ°'])
                
                # å¦‚æœæ˜¯çº¯é¢„æµ‹æŸ¥è¯¢ï¼ˆæ²¡æœ‰"ä¼˜åŒ–"ã€"æå‡"ã€"æ”¹è¿›"ç­‰è¯ï¼‰ï¼Œåˆ™åªé¢„æµ‹ä¸ä¼˜åŒ–
                if is_pure_prediction and not any(keyword in user_query for keyword in ['ä¼˜åŒ–', 'æå‡', 'æ”¹è¿›', 'è°ƒæ•´', 'å¢åŠ ', 'é™ä½']):
                    print(f"\n  â„¹ï¸  æ£€æµ‹åˆ°çº¯é¢„æµ‹æŸ¥è¯¢ï¼Œè¿”å›å½“å‰é…æ¯”çš„é¢„æµ‹å¼ºåº¦")
                    print(f"  ï¼ˆå¦‚éœ€ä¼˜åŒ–é…æ¯”ï¼Œè¯·åœ¨æŸ¥è¯¢ä¸­æ˜ç¡®æŒ‡å‡ºç›®æ ‡æˆ–è°ƒæ•´éœ€æ±‚ï¼‰")
                    
                    # ç›´æ¥è¿”å›åŸºå‡†å¼ºåº¦é¢„æµ‹ï¼Œä¸è¿›è¡Œä¼˜åŒ–
                    optimized_config = base_config.copy()
                    predicted_strength = base_strength
                else:
                    # ç”¨æˆ·æƒ³è¦ä¼˜åŒ–ä½†æ²¡æœ‰æŒ‡å®šå…·ä½“ç›®æ ‡ï¼Œä½¿ç”¨é»˜è®¤10%è°ƒæ•´
                    print(f"\n  ä½¿ç”¨é»˜è®¤è°ƒæ•´ç­–ç•¥ï¼ˆæ¯ä¸ªå˜é‡Â±10%ï¼‰")
                    for interv in top_interventions:
                        var = interv['variable']
                        effect = interv['causal_effect']
                        
                        if var in optimized_config:
                            current_val = optimized_config[var]
                            
                            if effect > 0:
                                new_val = current_val * 1.1
                                print(f"    â€¢ {var}: {current_val:.1f} â†’ {new_val:.1f} (â†‘10%, æ•ˆåº”: +{effect:.3f})")
                            else:
                                new_val = current_val * 0.9
                                print(f"    â€¢ {var}: {current_val:.1f} â†’ {new_val:.1f} (â†“10%, æ•ˆåº”: {effect:.3f})")
                            
                            optimized_config[var] = new_val
                    
                    # é¢„æµ‹ä¼˜åŒ–åçš„å¼ºåº¦
                    intervention_funcs = {
                        'cement': lambda x: optimized_config.get('cement', 280),
                        'blast_furnace_slag': lambda x: optimized_config.get('blast_furnace_slag', 0),
                        'fly_ash': lambda x: optimized_config.get('fly_ash', 0),
                        'water': lambda x: optimized_config.get('water', 180),
                        'superplasticizer': lambda x: optimized_config.get('superplasticizer', 0),
                        'coarse_aggregate': lambda x: optimized_config.get('coarse_aggregate', 1000),
                        'fine_aggregate': lambda x: optimized_config.get('fine_aggregate', 800),
                        'age': lambda x: optimized_config.get('age', 28)
                    }
                    
                    samples = gcm.interventional_samples(
                        _causal_model_instance.causal_model,
                        intervention_funcs,
                        num_samples_to_draw=100
                    )
                    
                    predicted_strength = float(samples['concrete_compressive_strength'].mean())
        
        else:
            # åäº‹å®åˆ†æï¼šåº”ç”¨å¹²é¢„å€¼åˆ°é…æ¯”
            if analysis_type == 'counterfactual' and 'interventions' in causal_results:
                # ä»åäº‹å®åˆ†æç»“æœä¸­æå–å¹²é¢„å€¼
                interventions_list = causal_results.get('interventions', [])
                print(f"\n  ğŸ“Š åº”ç”¨åäº‹å®å¹²é¢„:")
                for interv in interventions_list:
                    var = interv['variable']
                    old_val = interv['original_value']
                    new_val = interv['new_value']
                    if var in optimized_config:
                        optimized_config[var] = new_val
                        print(f"    â€¢ {var}: {old_val:.1f} â†’ {new_val:.1f}")
            
            # ä½¿ç”¨å¹²é¢„åçš„é…æ¯”é¢„æµ‹å¼ºåº¦
            intervention_funcs = {
                'cement': lambda x: optimized_config.get('cement', 280),
                'blast_furnace_slag': lambda x: optimized_config.get('blast_furnace_slag', 0),
                'fly_ash': lambda x: optimized_config.get('fly_ash', 0),
                'water': lambda x: optimized_config.get('water', 180),
                'superplasticizer': lambda x: optimized_config.get('superplasticizer', 0),
                'coarse_aggregate': lambda x: optimized_config.get('coarse_aggregate', 1000),
                'fine_aggregate': lambda x: optimized_config.get('fine_aggregate', 800),
                'age': lambda x: optimized_config.get('age', 28)
            }
            
            samples = gcm.interventional_samples(
                _causal_model_instance.causal_model,
                intervention_funcs,
                num_samples_to_draw=100
            )
            
            predicted_strength = float(samples['concrete_compressive_strength'].mean())
        
        strength_improvement = ((predicted_strength - base_strength) / base_strength) * 100 if base_strength != 0 else 0
        
        print(f"\n  âœ“ åŸºå‡†å¼ºåº¦: {base_strength:.2f} MPa")
        print(f"  âœ“ é¢„æµ‹å¼ºåº¦: {predicted_strength:.2f} MPa")
        print(f"  âœ“ å®é™…æå‡: {strength_improvement:+.1f}%")
        if target_improvement:
            error = abs(strength_improvement - target_improvement)
            print(f"  âœ“ ç›®æ ‡æå‡: {target_improvement:+.1f}%")
            print(f"  âœ“ è¯¯å·®: {error:.2f}ä¸ªç™¾åˆ†ç‚¹")
        
        # ç”Ÿæˆä¼˜åŒ–æ‘˜è¦
        optimization_summary = f"""
ä¼˜åŒ–é…æ¯”æ–¹æ¡ˆï¼š
  åŸºå‡†å¼ºåº¦: {base_strength:.2f} MPa
  ä¼˜åŒ–å¼ºåº¦: {predicted_strength:.2f} MPa
  å®é™…æå‡: {strength_improvement:+.1f}%
{"  ç›®æ ‡æå‡: " + f"{target_improvement:+.1f}%" if target_improvement else ""}

å»ºè®®é…æ¯”ï¼š
  â€¢ æ°´æ³¥: {optimized_config.get('cement', 0):.1f} kg/mÂ³
  â€¢ é«˜ç‚‰çŸ¿æ¸£: {optimized_config.get('blast_furnace_slag', 0):.1f} kg/mÂ³
  â€¢ ç²‰ç…¤ç°: {optimized_config.get('fly_ash', 0):.1f} kg/mÂ³
  â€¢ æ°´: {optimized_config.get('water', 0):.1f} kg/mÂ³
  â€¢ é«˜æ•ˆå‡æ°´å‰‚: {optimized_config.get('superplasticizer', 0):.1f} kg/mÂ³
  â€¢ ç²—éª¨æ–™: {optimized_config.get('coarse_aggregate', 0):.1f} kg/mÂ³
  â€¢ ç»†éª¨æ–™: {optimized_config.get('fine_aggregate', 0):.1f} kg/mÂ³
  â€¢ é¾„æœŸ: {optimized_config.get('age', 28):.0f} å¤©
"""
        
        return {
            "optimized_config": optimized_config,
            "predicted_strength": predicted_strength,
            "optimization_summary": optimization_summary
        }
        
    except Exception as e:
        print(f"  âš ï¸  ä¼˜åŒ–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return {
            "optimized_config": None,
            "predicted_strength": None,
            "optimization_summary": f"ä¼˜åŒ–å¤±è´¥: {e}"
        }


def advisor_agent(state: CausalAnalysisState) -> dict:
    """
    Advisor Agentï¼šè§£è¯»å› æœåˆ†æç»“æœï¼Œç”Ÿæˆå†³ç­–å»ºè®®
    
    èŒè´£ï¼š
    1. ç†è§£å› æœåˆ†æçš„æ•°å€¼ç»“æœ
    2. ç”Ÿæˆé€šä¿—æ˜“æ‡‚çš„è§£é‡Š
    3. æä¾›å¯æ“ä½œçš„å·¥è‰ºä¼˜åŒ–å»ºè®®
    """
    print("\nğŸ’¡ Advisor Agent æ­£åœ¨ç”Ÿæˆå†³ç­–å»ºè®®...")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯
    if state.get('error'):
        return {
            "recommendations": f"åˆ†æè¿‡ç¨‹å‡ºç°é”™è¯¯ï¼Œæ— æ³•ç”Ÿæˆå»ºè®®ã€‚é”™è¯¯ä¿¡æ¯ï¼š{state['error']}"
        }
    
    # ä½¿ç”¨ LLM ç”Ÿæˆå»ºè®®
    llm = ChatOpenAI(
        model=OPENAI_MODEL,
        temperature=0.3,
        openai_api_key=OPENAI_API_KEY,
        base_url=OPENAI_API_BASE
    )
    
    import json
    
    # å‡†å¤‡ä¼˜åŒ–é…æ¯”ä¿¡æ¯
    optimization_info = ""
    if state.get('optimized_config') and state.get('predicted_strength'):
        optimization_info = f"""

ä¼˜åŒ–é…æ¯”æ–¹æ¡ˆï¼š
{state.get('optimization_summary', '')}"""
    
    prompt = f"""ä½ æ˜¯ä¸€ä¸ªæ··å‡åœŸé…åˆæ¯”ä¼˜åŒ–çš„ä¸“å®¶é¡¾é—®ã€‚è¯·åŸºäºå› æœåˆ†æç»“æœï¼Œç”Ÿæˆå®ç”¨çš„å†³ç­–å»ºè®®ã€‚

åº”ç”¨åœºæ™¯ï¼šé«˜æ€§èƒ½æ··å‡åœŸé…åˆæ¯”è®¾è®¡ä¸å¼ºåº¦ä¼˜åŒ–
æ•°æ®æ¥æºï¼šUCI Machine Learning Repository (Yeh 1998, 1030ä¸ªçœŸå®æ ·æœ¬)

ç”¨æˆ·é—®é¢˜ï¼š{state['user_query']}

åˆ†æç±»å‹ï¼š{state['analysis_type']}
åˆ†ææ‘˜è¦ï¼š{state['analysis_summary']}

è¯¦ç»†ç»“æœï¼š
{json.dumps(state['causal_results'], indent=2, ensure_ascii=False)}
{optimization_info}

å…³é”®å˜é‡è¯´æ˜ï¼ˆåŸºäºUCIçœŸå®æ•°æ®é›†ï¼Œ9ä¸ªåŸå§‹å˜é‡ï¼‰ï¼š
- concrete_compressive_strength: æŠ—å‹å¼ºåº¦ï¼ˆMPaï¼‰**ã€ç›®æ ‡å˜é‡ã€‘** - 2.3-82.6ï¼Œå‡å€¼35.8
- cement: æ°´æ³¥ï¼ˆkg/mÂ³ï¼‰**ã€å…³é”®ææ–™ã€‘** - 102-540ï¼Œå‡å€¼281
- blast_furnace_slag: é«˜ç‚‰çŸ¿æ¸£ï¼ˆkg/mÂ³ï¼‰- 0-359ï¼Œå‡å€¼74ï¼Œæ”¹å–„å¯†å®åº¦å’Œè€ä¹…æ€§
- fly_ash: ç²‰ç…¤ç°ï¼ˆkg/mÂ³ï¼‰- 0-200ï¼Œå‡å€¼54ï¼Œç«å±±ç°ååº”ï¼Œé•¿æœŸå¼ºåº¦
- water: æ°´ï¼ˆkg/mÂ³ï¼‰**ã€Abramså®šå¾‹ï¼šæ°´è¶Šå¤šå¼ºåº¦è¶Šä½ã€‘** - 122-247ï¼Œå‡å€¼182
- superplasticizer: é«˜æ•ˆå‡æ°´å‰‚ï¼ˆkg/mÂ³ï¼‰- 0-32ï¼Œå‡å€¼6.2ï¼Œä¸æ°´è´Ÿç›¸å…³ï¼ˆr=-0.66ï¼‰
- coarse_aggregate: ç²—éª¨æ–™ï¼ˆkg/mÂ³ï¼‰- 801-1145ï¼Œå‡å€¼973
- fine_aggregate: ç»†éª¨æ–™ï¼ˆkg/mÂ³ï¼‰- 594-993ï¼Œå‡å€¼774
- age: é¾„æœŸï¼ˆå¤©ï¼‰**ã€æ—¶é—´æ•ˆåº”ã€‘** - 1-365ï¼Œå‡å€¼46

æ°´èƒ¶æ¯”è®¡ç®—å…¬å¼ï¼šwater / (cement + blast_furnace_slag + fly_ash)
æ¨èæ°´èƒ¶æ¯”èŒƒå›´ï¼š0.35-0.50ï¼ˆè¶Šä½å¼ºåº¦è¶Šé«˜ï¼‰

è¯·æä¾›ï¼š
1. **æ ¸å¿ƒå‘ç°**ï¼šç”¨1-2å¥è¯æ€»ç»“æœ€é‡è¦çš„å‘ç°
2. **å…·ä½“å»ºè®®**ï¼šæä¾›3-5æ¡å¯æ“ä½œçš„æ”¹è¿›æªæ–½ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
   - æ˜ç¡®æŒ‡å‡ºåº”è¯¥è°ƒæ•´å“ªä¸ªå‚æ•°
   - è¯´æ˜è°ƒæ•´æ–¹å‘å’Œå¹…åº¦
   - é¢„æœŸæ•ˆæœ
3. **å®æ–½æ–¹æ¡ˆ**ï¼šå»ºè®®çš„å®æ–½é¡ºåºå’Œæ³¨æ„äº‹é¡¹
4. **é£é™©æç¤º**ï¼šå¯èƒ½çš„å‰¯ä½œç”¨æˆ–éœ€è¦ç›‘æ§çš„æŒ‡æ ‡

è¯·ç”¨ä¸“ä¸šä½†é€šä¿—çš„è¯­è¨€ï¼Œç¡®ä¿å»ºè®®å…·æœ‰å¯æ“ä½œæ€§ã€‚
"""
    
    response = llm.invoke(prompt)
    recommendations = response.content
    
    return {
        "recommendations": recommendations
    }


def _generate_analysis_summary(result: dict) -> str:
    """ç”Ÿæˆåˆ†æç»“æœçš„ç®€è¦æ‘˜è¦"""
    analysis_type = result.get('type', 'unknown')
    
    if analysis_type == 'attribution':
        top_factors = result.get('top_factors', [])
        if top_factors:
            top_3 = top_factors[:3]
            summary = f"å½’å› åˆ†æå®Œæˆã€‚ä¸»è¦å½±å“å› ç´ ï¼š" + "ã€".join([
                f"{f['variable']}(è´¡çŒ®{f['contribution']:.4f})" 
                for f in top_3
            ])
        else:
            summary = "å½’å› åˆ†æå®Œæˆï¼Œä½†æœªå‘ç°æ˜¾è‘—å½±å“å› ç´ ã€‚"
            
    elif analysis_type == 'intervention':
        interventions = result.get('interventions', [])
        if interventions:
            top_3 = sorted(interventions, key=lambda x: abs(x['causal_effect']), reverse=True)[:3]
            summary = f"å¹²é¢„åˆ†æå®Œæˆã€‚æœ€æœ‰æ•ˆçš„å¹²é¢„æªæ–½ï¼š" + "ã€".join([
                f"{i['variable']}(æ•ˆåº”{i['causal_effect']:.4f})"
                for i in top_3
            ])
        else:
            summary = "å¹²é¢„åˆ†æå®Œæˆï¼Œä½†æœªå‘ç°æœ‰æ•ˆçš„å¹²é¢„æªæ–½ã€‚"
            
    elif analysis_type == 'counterfactual':
        effect = result.get('causal_effect', 0)
        interventions_list = result.get('interventions', [])
        
        if len(interventions_list) == 1:
            # å•å˜é‡å¹²é¢„
            interv = interventions_list[0]
            summary = f"åäº‹å®åˆ†æå®Œæˆã€‚å¦‚æœ{interv['variable']}ä»" \
                      f"{interv['original_value']:.4f}æ”¹ä¸º{interv['new_value']:.4f}ï¼Œ" \
                      f"{result['target']}é¢„æœŸå˜åŒ–{effect:.4f}ã€‚"
        else:
            # å¤šå˜é‡å¹²é¢„
            interv_desc = "ã€".join([
                f"{i['variable']}={i['new_value']:.2f}" 
                for i in interventions_list
            ])
            summary = f"åäº‹å®åˆ†æå®Œæˆã€‚å¦‚æœå¹²é¢„{interv_desc}ï¼Œ" \
                      f"{result['target']}é¢„æœŸå˜åŒ–{effect:.4f}ã€‚"
    else:
        summary = "åˆ†æå®Œæˆã€‚"
    
    return summary


# ============================================================================
# ç¬¬å››æ­¥ï¼šæ„å»º LangGraph Workflow
# ============================================================================

def create_causal_agent_graph():
    """åˆ›å»ºå› æœåˆ†ææ™ºèƒ½ä½“å·¥ä½œæµ"""
    
    # åˆ›å»ºçŠ¶æ€å›¾
    workflow = StateGraph(CausalAnalysisState)
    
    # æ·»åŠ å››ä¸ªæ™ºèƒ½ä½“èŠ‚ç‚¹
    workflow.add_node("router", router_agent)
    workflow.add_node("analyst", causal_analyst_agent)
    workflow.add_node("optimizer", optimizer_agent)  # æ–°å¢ä¼˜åŒ–å™¨èŠ‚ç‚¹
    workflow.add_node("advisor", advisor_agent)
    
    # å®šä¹‰æµç¨‹ï¼šSTART â†’ Router â†’ Analyst â†’ Optimizer â†’ Advisor â†’ END
    workflow.add_edge(START, "router")
    workflow.add_edge("router", "analyst")
    workflow.add_edge("analyst", "optimizer")  # åˆ†æåä¼˜åŒ–
    workflow.add_edge("optimizer", "advisor")  # ä¼˜åŒ–åå»ºè®®
    workflow.add_edge("advisor", END)
    
    # ç¼–è¯‘å·¥ä½œæµ
    app = workflow.compile()
    
    return app


# ============================================================================
# å¯¼å‡ºæ¥å£
# ============================================================================

__all__ = [
    'CausalAnalysisState',
    'initialize_causal_model',
    'create_causal_agent_graph',
    'router_agent',
    'causal_analyst_agent',
    'optimizer_agent',
    'advisor_agent',
    'math_calculator_tool'
]

